{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "pB9yInwQXEss",
        "cS8WLimG311M",
        "XODmuJE76kq2",
        "_zWEnvIHHqan",
        "uwZTcBg-5Hcz",
        "stuXo8hmISB-",
        "IsFUifm96qgA",
        "su23mkjq60K0",
        "zqILNcp1Juxb",
        "0AkJ0x-v7tN3",
        "_DZoDyNMLPBD",
        "cC4-ZtVRBV-o",
        "1-Eq1v_iEc0h",
        "vGMktUrSExw_",
        "nJZbQfhJSsCP",
        "Plo2xlx9G7am",
        "_VrvXHyxX0At",
        "rwoEopHGawuF",
        "jh5mR_qUK_lL",
        "FPCfMLwgt6kT",
        "ffjv6MmdPnEb",
        "hMZ-Z_3T2C82",
        "MaLKYA8dRQea",
        "gDJujHFb4BNj",
        "WxZkQnVXTByw",
        "wwf1RZL1TRDR",
        "c5q0d9vo7NVH",
        "DuOQRL4m-tcK"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPRfOWflj8sTy35jCBIoTQa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/askoki/football-mock-data/blob/main/%5Bworksheet%5D_DSC_Europe_football_workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Think You Can Handle Football Player Data? Join the Clubâ€™s Data Lab\n",
        "\n",
        "Welcome to the Data Lab session, where weâ€™ll walk through the exciting world of football player data analysis. Get ready to:\n",
        "\n",
        "1. **Load and Clean GPS Datasets**  \n",
        "   - Learn how to import and prepare GPS data for analysis.\n",
        "   - Fix formatting issues and create new features.\n",
        "\n",
        "2. **Visualize Player Data**  \n",
        "   - Learn how to plot key metrics and trends using simple and powerful visualizations.\n",
        "\n",
        "3. **Calculate and Visualize Exponential Weighted Moving Averages (EWMA)**  \n",
        "   - Understand how to smooth performance data over time and visualize it through the season.\n",
        "\n",
        "4. **Analyze Winter Conditioning Period**  \n",
        "   - Dive into the winter conditioning phase to visualize the teamâ€™s workload and track progress.\n",
        "\n",
        "5. **Create a Player Progress Report**  \n",
        "   - Build a report that allows coaches to compare a player's current performance with their season-best data.\n",
        "\n",
        "By the end of this session, youâ€™ll be able to analyze and visualize player data like a pro, helping coaches and analysts make smarter decisions for the season.\n",
        "---"
      ],
      "metadata": {
        "id": "pB9yInwQXEss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Dataset Loading and Initial Exploration\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "cS8WLimG311M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Data Loading"
      ],
      "metadata": {
        "id": "XODmuJE76kq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "1fzb4odhGnmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UxfwR5AGYa5"
      },
      "outputs": [],
      "source": [
        "DATA_URL = 'https://raw.githubusercontent.com/askoki/football-mock-data/refs/heads/main/FC_Europe_dataset.csv'\n",
        "df = pd.read_csv(DATA_URL)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Jo2bTej2Gi7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "df.describe()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "wCGaMPLkHJXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Dataset Inspection Task\n",
        "\n",
        "In this session, weâ€™ll conduct an initial exploratory analysis of the dataset, focusing on key structural insights:\n",
        "\n",
        "1. **Player Count**  \n",
        "   - Determine the total number of unique players represented in the dataset.\n",
        "\n",
        "2. **Data Points per Player**  \n",
        "   - Identify the number of data entries associated with each player, providing a breakdown of data density across players.\n",
        "\n",
        "3. **Session Coverage**  \n",
        "   - Calculate the number of distinct days where sessions took place, giving insight into session frequency and consistency over time."
      ],
      "metadata": {
        "id": "_zWEnvIHHqan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.player.unique()"
      ],
      "metadata": {
        "id": "NTM_Yk1GGzdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.player.unique().shape"
      ],
      "metadata": {
        "id": "c9oOetIRHmFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.player.value_counts()"
      ],
      "metadata": {
        "id": "QU1-SxwWH702"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Date Inspection and Formatting Correction\n",
        "\n",
        "Next, we'll examine the date data for any inconsistencies or errors in formatting.\n",
        "\n",
        "ðŸ“Œ **Task:** Review the date entries to detect any anomalies, such as incorrect formats, missing dates, or out-of-sequence entries.\n",
        "\n",
        "### Hint:\n",
        "To help identify any issues with the date data, try using some of the functions we've previously applied to inspect the player data:\n",
        "- Use `describe()` to get an overview of the date field.\n",
        "- Apply `min()` and `max()` to find the earliest and latest dates, helping to spot any unexpected outliers.\n",
        "- Use `unique()` with `shape` to check the variety of date formats. Do they make sense?\n",
        "\n",
        "By addressing these potential formatting issues, weâ€™ll improve the dataset's reliability and prepare it for accurate analysis in further stages."
      ],
      "metadata": {
        "id": "uwZTcBg-5Hcz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PoyBUVyiH_Ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-eAteo4HICVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mi18_5k5IK4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mv7jSa1jIOYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data Cleaning and Date Formatting\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "stuXo8hmISB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Fixing Date Format\n",
        "\n",
        "Weâ€™ll standardize the dates to a uniform format (e.g., `YYYY-MM-DD`) to ensure consistency across the dataset."
      ],
      "metadata": {
        "id": "IsFUifm96qgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.date.dtypes"
      ],
      "metadata": {
        "id": "t2fo_lG3IPrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.date.iloc[0]"
      ],
      "metadata": {
        "id": "if-0ebXjx3gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.date = df.date.str.replace('.', '-')"
      ],
      "metadata": {
        "id": "5UdKw9P8IaB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.date.unique().shape"
      ],
      "metadata": {
        "id": "b1i22lreJdsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "id": "_hlBMfys61Rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Date Sorting"
      ],
      "metadata": {
        "id": "su23mkjq60K0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sort_values('date')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "eAGxrES6IpYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.reset_index(inplace=True, drop=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "nB2fSV03Jnic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Data cleaning\n",
        "\n",
        "### Goal: Inspecting Session Types\n",
        "\n",
        "Our first step in data cleaning is to understand the distribution of session types in the dataset. Weâ€™ll start by exploring which session types are present and how frequently each occurs.\n",
        "\n",
        "**ðŸ“Œ Task**: Use the following command to check the frequency of each session type:\n",
        "```python\n",
        "df.session_type.value_counts()\n",
        "```"
      ],
      "metadata": {
        "id": "zqILNcp1Juxb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9HDouuQTJpip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.1 Adjusting Session Types Based on Coach Feedback\n",
        "\n",
        "Based on the coachâ€™s review, certain `OFFICIAL MATCHES` were actually friendly matches during specified periods. We need to update these entries to ensure accurate categorization.\n",
        "\n",
        "#### Coachâ€™s Instruction:\n",
        "- Update all sessions labeled as `OFFICIAL MATCHES` in the date ranges:\n",
        "  - **15.6.2024 to 26.7.2024**\n",
        "  - **1.1.2025 to 29.1.2025**\n",
        "\n",
        "These sessions should be reclassified as `FRIENDLY MATCHES`.\n",
        "\n",
        "**ðŸ“Œ Task:**  \n",
        "The `replace_session_type` function is already implemented to perform this update. Your task is to try running the function and identify any issues that may arise."
      ],
      "metadata": {
        "id": "0AkJ0x-v7tN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, date\n",
        "\n",
        "def replace_session_type(df: pd.DataFrame, start_date: datetime.date, end_date: datetime.date) -> pd.DataFrame:\n",
        "    df.loc[\n",
        "        (df['date'] >= start_date) &\n",
        "        (df['date'] <= end_date) &\n",
        "        (df['session_type'] == 'OFFICIAL MATCH'),\n",
        "        'session_type'\n",
        "    ] = 'FRIENDLY MATCH'\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "tmiH9tYxJ3nA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = replace_session_type(df, date(2024, 6, 15), date(2024, 7, 26))"
      ],
      "metadata": {
        "id": "2Esvj3GbKz9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.2 Inspecting Data Types and Fixing Date Format"
      ],
      "metadata": {
        "id": "_DZoDyNMLPBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.date.iloc[0]"
      ],
      "metadata": {
        "id": "XIoPtwqaLgWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(df.date.iloc[0])"
      ],
      "metadata": {
        "id": "Qw5OF7nEAONx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.date = pd.to_datetime(df.date).dt.date"
      ],
      "metadata": {
        "id": "1KhdSo6kK69z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.date.iloc[0]"
      ],
      "metadata": {
        "id": "1LFn3QWxLaU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(df.date.iloc[0])"
      ],
      "metadata": {
        "id": "epHuMFDwAG2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = replace_session_type(df, date(2024, 6, 15), date(2024, 7, 26))"
      ],
      "metadata": {
        "id": "a2PR3eVcLTon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ðŸ“Œ Task:**\n",
        "- Update Training Labels for the Winter Preseason Period â€“ **1.1.2025 to 29.1.2025**\n",
        "- Check which session types are now present in the dataset?"
      ],
      "metadata": {
        "id": "NOCot9x7LwWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nTtB0c3gLswv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xt386A8wMA0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Average Load Calculation\n",
        "\n",
        "---\n",
        "At the end of the season, coaches rely on our analysis to evaluate the training load throughout the season. This helps identify areas where fitness levels can be improved and where injury risk can be reduced.\n",
        "\n"
      ],
      "metadata": {
        "id": "cC4-ZtVRBV-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('date').size()"
      ],
      "metadata": {
        "id": "rGiOz_YrMD0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "ptFc4EiLQcGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1  What was the average load across the season?\n",
        "\n",
        "We need the following in order to achieve that:\n",
        "\n",
        "1. Compute the daily average load for across all sessions (e.g., training or match).\n",
        "2. Visualize the results using a plot."
      ],
      "metadata": {
        "id": "1-Eq1v_iEc0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('date').agg({\n",
        "    'session_type': 'first',\n",
        "    'duration': 'mean',\n",
        "    'total_distance_m': 'mean'\n",
        "})"
      ],
      "metadata": {
        "id": "3Q4LVpYlQTzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ðŸ“Œ Task:** Can you spot the issue?"
      ],
      "metadata": {
        "id": "TjMAsfJSQ0uy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bwv_zxGHQzPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.1 Side Quest: Fix Non-Numeric Data Issues"
      ],
      "metadata": {
        "id": "vGMktUrSExw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.duration.iloc[0]"
      ],
      "metadata": {
        "id": "z2eg6pPvQ5Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duration.dtypes"
      ],
      "metadata": {
        "id": "P14CP8crRHNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[:, 'duration_min'] = pd.to_timedelta(df.duration).dt.total_seconds() / 60\n",
        "df.loc[:, 'duration_min'] = df.duration_min.astype(int)"
      ],
      "metadata": {
        "id": "XZbNAezARIeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns='duration')"
      ],
      "metadata": {
        "id": "tKK9SP1hR8Qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "id": "5LHVDh900-8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.2 Back to Computing Daily Average\n",
        "\n",
        "ðŸ“Œ **Task:** Use the previously demonstrated `groupby` method to calculate the average per date and store the results in `avg_df`. The aggregation should be performed as follows:\n",
        "\n",
        "- `session_type`: first\n",
        "- `duration_min`: mean\n",
        "- `total_distance_m`: mean\n",
        "\n"
      ],
      "metadata": {
        "id": "nJZbQfhJSsCP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n1gxRBLYSwWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Visualization Time\n",
        "\n",
        "Great job on the data cleaning! Now, let's showcase our results using the prepared `plot_gps_param` function."
      ],
      "metadata": {
        "id": "Plo2xlx9G7am"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.dates as mdates\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "def plot_gps_param(df: pd.DataFrame, param_name: str, title: str) -> None:\n",
        "  fig, ax = plt.subplots(figsize=(14, 3), sharex=True)\n",
        "  fig.suptitle(title, fontsize=12, color='Black')\n",
        "\n",
        "  x = avg_df.date.values\n",
        "  y = avg_df[param_name].values\n",
        "\n",
        "  ax.bar(x, y, label=param_name)\n",
        "\n",
        "  ax.xaxis.set_major_locator(mdates.WeekdayLocator(byweekday=mdates.MO))\n",
        "  ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
        "  plt.xticks(rotation=45)\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "GN6DeRxeS9jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_gps_param(avg_df, 'total_distance_m', 'Average across the season')"
      ],
      "metadata": {
        "id": "Ec3NQH1TUmBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.1 Visualizing the Difference Between Trainings and Matches\n",
        "\n",
        "The coach has requested that we visualize the difference between training sessions and matches. To achieve this, we need to:\n",
        "\n",
        "1. Add a boolean column `is_match` to easily differentiate between the two.\n",
        "2. Modify the `plot_gps_param` function to visualize the data using two distinct bar plots for training sessions and matches."
      ],
      "metadata": {
        "id": "_VrvXHyxX0At"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_df.session_type.value_counts()"
      ],
      "metadata": {
        "id": "tyduShz2YKRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_df.loc[:, 'is_match'] = avg_df.apply(lambda r: False if r.session_type == 'FULL TRAINING' else True, axis=1)\n",
        "avg_df.is_match.value_counts()"
      ],
      "metadata": {
        "id": "iDyH2xAnXxq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ggplot_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
        "\n",
        "primary_color = ggplot_colors[0]\n",
        "secondary_color = ggplot_colors[1]"
      ],
      "metadata": {
        "id": "FPa_ObicJdhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_gps_param(df: pd.DataFrame, param_name: str, title: str) -> None:\n",
        "  fig, ax = plt.subplots(figsize=(14, 4), sharex=True)\n",
        "  fig.suptitle(title, fontsize=16)\n",
        "\n",
        "  training_df = df[df.is_match == False]\n",
        "  match_df = df[df.is_match == True]\n",
        "\n",
        "  ax.bar(training_df.date.values, training_df[param_name].values, color=primary_color, label='Trainings')\n",
        "  ax.bar(match_df.date.values, match_df[param_name].values, color=secondary_color, label='Matches')\n",
        "\n",
        "  ax.xaxis.set_major_locator(mdates.WeekdayLocator(byweekday=mdates.MO))\n",
        "  ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
        "  plt.xticks(rotation=45)\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "lAYOTP9TUtwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_gps_param(avg_df, 'total_distance_m', 'Average across the season')"
      ],
      "metadata": {
        "id": "ctkTfF2kZq0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Exponential Weighted Moving Average (EWMA)\n",
        "\n",
        "Training sessions vary, and the load fluctuates as the season progresses. To get a clearer overview, we need to smooth the data. Since more recent training load values are more relevant than older ones (e.g., the load from three months ago), the Exponential Weighted Moving Average (EWMA) is a commonly used technique. In this section, we'll explore how EWMA works and how it can help us better understand the data."
      ],
      "metadata": {
        "id": "rwoEopHGawuF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3.1 EWMA Example"
      ],
      "metadata": {
        "id": "jh5mR_qUK_lL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_LENGTH = 30\n",
        "\n",
        "data_x = np.arange(DATA_LENGTH)\n",
        "data_y = np.random.rand(1, data_x.shape[0]) * 100\n",
        "data_y = data_y.astype(int)[0]\n",
        "\n",
        "example_df = pd.DataFrame({'x': data_x, 'y': data_y})"
      ],
      "metadata": {
        "id": "BlhB8yZacUdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('default')"
      ],
      "metadata": {
        "id": "syMW7u4eLhDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(4,3))\n",
        "plt.bar(example_df.x, example_df.y)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u6HAiZITZs0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ewma_window_5 = example_df.y.ewm(5).mean().values\n",
        "ewma_window_5"
      ],
      "metadata": {
        "id": "lByaQr7kcCZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(4,3))\n",
        "plt.bar(example_df.x, example_df.y, label='Mock Data')\n",
        "plt.plot(example_df.x, ewma_window_5, color='black', linestyle='--', label='EWMA (window=5)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eB7i3Y18egWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ“Œ **Task:** Modify the `plot_gps_param` function to plot the Exponential Weighted Moving Average (EWMA) values for the specified parameter (`param_name`) across the season, using a 14-day window. You can plot the values with the following code, just replace `x` and `y` with the corresponding values:\n",
        "\n",
        "```python\n",
        "ax.plot(x, y, color='black', linestyle='--', label='EWMA (14 days)')\n"
      ],
      "metadata": {
        "id": "W1NvBciZeXDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_gps_param(df: pd.DataFrame, param_name: str, title: str) -> None:\n",
        "  fig, ax = plt.subplots(figsize=(14, 4), sharex=True)\n",
        "  fig.suptitle(title, fontsize=16)\n",
        "\n",
        "  training_df = df[df.is_match == False]\n",
        "  match_df = df[df.is_match == True]\n",
        "\n",
        "  ax.bar(training_df.date.values, training_df[param_name].values, color=primary_color, label='Trainings')\n",
        "  ax.bar(match_df.date.values, match_df[param_name].values, color=secondary_color, label='Matches')\n",
        "  # ---------------- ADD CODE HERE ----------------\n",
        "  x = df.date.values\n",
        "  y = # you need to write it\n",
        "  # plotting\n",
        "  # ----------------  END OF CODE ----------------\n",
        "  ax.xaxis.set_major_locator(mdates.WeekdayLocator(byweekday=mdates.MO))\n",
        "  ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
        "  plt.xticks(rotation=45)\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "zj_uk5qqdmhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_gps_param(avg_df, 'total_distance_m', 'Average across the season')"
      ],
      "metadata": {
        "id": "7TWv_FMPfO0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Weekly Data Aggregation for Team\n",
        "\n",
        "---\n",
        "\n",
        "Now that we have an overall picture of the season, let's shift focus to a more frequent scenario. Imagine being in the middle of the season, where you need to estimate the load for the upcoming week. We will place ourselves at the end of the winter preparation period (from 1st January 2025 to 29th January 2025) and explore how to visualize cumulative training load to assist strength and conditioning coaches in planning their work."
      ],
      "metadata": {
        "id": "FPCfMLwgt6kT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[:, 'is_match'] = df.apply(lambda r: False if r.session_type == 'FULL TRAINING' else True, axis=1)\n",
        "zoom_df = df[df.date < date(2025, 1, 29)]\n",
        "zoom_df.tail(5)"
      ],
      "metadata": {
        "id": "HztdMf7Mt5pU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Selecting the Time Span"
      ],
      "metadata": {
        "id": "ffjv6MmdPnEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import timedelta\n",
        "\n",
        "date_until = zoom_df.date.max()\n",
        "date_from = date_until- timedelta(days=28)\n",
        "weeks4_df = zoom_df[(zoom_df.date >= date_from) & (zoom_df.date <= date_until)]\n",
        "weeks4_df"
      ],
      "metadata": {
        "id": "5faTdnaL19Bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Average Load per Week for the Last 4 Weeks\n",
        "\n",
        "ðŸ“Œ **Task:** Begin by grouping the sessions by date and use only the `cols2inspect` columns for aggregation. You can do this using the following code:\n",
        "```python\n",
        "weeks4_df.groupby('date', as_index=False)[cols2inspect]\n",
        "```\n",
        "Then, aggregate all parameters by taking the mean using `.agg('mean')` and store it into variable `day_mean_df`.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "hMZ-Z_3T2C82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols2inspect = [\n",
        "    'total_distance_m', 'HSR_m', 'sprint_m', 'acc_cnt', 'dec_cnt', 'player_load'\n",
        "]"
      ],
      "metadata": {
        "id": "GLTvaxak2Y9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rs4WwJG106cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.1 Adding Week Numbers for Grouping\n",
        "\n",
        "Next, we will add a week number column to the DataFrame, allowing us to group the data by week."
      ],
      "metadata": {
        "id": "MaLKYA8dRQea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "day_mean_df.loc[:, 'week'] = day_mean_df.date.apply(lambda r: r.isocalendar()[1])"
      ],
      "metadata": {
        "id": "w8W8yBR8usQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "day_mean_df"
      ],
      "metadata": {
        "id": "OVLRW5QH3gWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we can group the data by week and calculate the sum of the values."
      ],
      "metadata": {
        "id": "NH4pDBMtRsux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weeks4_df = day_mean_df.drop(columns='date').groupby('week', as_index=False).agg(np.sum)\n",
        "weeks4_df"
      ],
      "metadata": {
        "id": "JLJPDTRW3fkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(weeks4_df.week, weeks4_df.total_distance_m)\n",
        "plt.xlabel('Weeks')\n",
        "plt.ylabel('Total Distance (m)')"
      ],
      "metadata": {
        "id": "I4Nm5ewPR8Zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 More sophisticated approach\n",
        "\n",
        "Let's show the numbers in comparison to top 5 matches that the team has played up until this point in season. This will allow coach for easier understanding of these numbers in comparison to the desired output and that is match perofrmance."
      ],
      "metadata": {
        "id": "gDJujHFb4BNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_df = df.groupby('date')[cols2inspect + ['is_match']].agg(np.mean).reset_index()\n",
        "avg_df.head(3)"
      ],
      "metadata": {
        "id": "bXNu9nIB5EHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3.1 Calculating the Mean of the Top 5 Matches\n",
        "\n",
        "Now, let's calculate the mean of the top 5 matches the team has played to date."
      ],
      "metadata": {
        "id": "WxZkQnVXTByw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "match_ref_df = pd.DataFrame(index=[0])\n",
        "match_df = avg_df[avg_df.is_match == True]\n",
        "for col in cols2inspect:\n",
        "  best5_df = match_df.sort_values(col, ascending=False)[col].values[:5]\n",
        "  match_ref_df.loc[:, col] = best5_df.mean()\n",
        "match_ref_df"
      ],
      "metadata": {
        "id": "9tMJ6jYX3l0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3.2 Estimating Weekly Load Distribution Using `match_ref_df`\n",
        "\n",
        "For each observed parameter, we will divide the values by those in the `match_ref_df`. The results will be displayed in a stacked bar chart with four levels stacked on top of each other. To achieve this, we will divide the resulting values by 4.\n",
        "\n"
      ],
      "metadata": {
        "id": "wwf1RZL1TRDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "relative_df = weeks4_df.copy()\n",
        "for param in cols2inspect:\n",
        "    relative_df.loc[:, param] /= match_ref_df.loc[:, param].values\n",
        "    # We will be stacking four parameters on the graph later so we need to adjust the values.\n",
        "    NUMBER_OF_ITEMS_STACKED = 4\n",
        "    relative_df.loc[:, param] /= NUMBER_OF_ITEMS_STACKED\n",
        "relative_df = relative_df.round(2)"
      ],
      "metadata": {
        "id": "I513jFrK6qJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "relative_df"
      ],
      "metadata": {
        "id": "mHdeadOH7Frs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3.3 Plotting time"
      ],
      "metadata": {
        "id": "c5q0d9vo7NVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DARK_GRAY = '#7f7f7f'\n",
        "LIGHT_GRAY = '#d9d9d9'\n",
        "fill_design = [\n",
        "    (DARK_GRAY, True, None, 0.6),\n",
        "    (LIGHT_GRAY, True, None, 0.6),\n",
        "    (None, False, '///', 0.6),\n",
        "    (None, False, '..', 0.2),\n",
        "    (None, False, 'OO', 0.2),\n",
        "    (None, False, '', 0.2)\n",
        "]"
      ],
      "metadata": {
        "id": "xzw-NP-l7LYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('default')"
      ],
      "metadata": {
        "id": "5U_ymzJX9rKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "from datetime import timedelta\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6), facecolor='white')\n",
        "fig.suptitle(f'Team 4-week report', fontsize=18, weight='bold')\n",
        "facecolor = \"white\"\n",
        "fig.set_facecolor(facecolor)\n",
        "\n",
        "bottom = None\n",
        "\n",
        "for i, param in enumerate(cols2inspect):\n",
        "    color, fill, hatch, width = fill_design[i]\n",
        "\n",
        "    x_values = relative_df.week.astype(float).values.copy()\n",
        "    x_offset = 0.2\n",
        "\n",
        "    if i == 3:\n",
        "        x_values -= x_offset\n",
        "    elif i == 5:\n",
        "        x_values += x_offset\n",
        "\n",
        "    ax.bar(\n",
        "        x_values,\n",
        "        relative_df[param],\n",
        "        width=width,\n",
        "        label=param,\n",
        "        bottom=bottom,\n",
        "        color=color,\n",
        "        fill=fill,\n",
        "        hatch=hatch,\n",
        "    )\n",
        "    if param == cols2inspect[0]:\n",
        "        bottom = relative_df[param].values.copy()\n",
        "    elif i < 3:\n",
        "        bottom += relative_df[param].values\n",
        "\n",
        "ax.set_ylim(ymin=0, ymax=6)\n",
        "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
        "\n",
        "x_tick_labels, y_tick_labels = ax.get_xticklabels(), ax.get_yticklabels()\n",
        "for x_tick_label  in x_tick_labels:\n",
        "    x_tick_label.set_fontsize(12)\n",
        "for y_tick_label  in y_tick_labels:\n",
        "    y_tick_label.set_fontsize(12)\n",
        "\n",
        "ax.set_ylabel('Game Reference', fontsize=12, weight='bold')\n",
        "ax.set_xlabel('Weeks', fontsize=12, weight='bold')\n",
        "\n",
        "ax.legend(\n",
        "    loc='upper center', labels=cols2inspect,\n",
        "    bbox_to_anchor=(0.5, 1.05), ncol=3, fancybox=True, shadow=True,\n",
        "    fontsize=10\n",
        ")\n",
        "\n",
        "\n",
        "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "plt.xticks(rotation=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6K8Emikq7L7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Player-Level Analysis and Session Reports\n",
        "\n",
        "In this section, we'll focus on helping strength and conditioning coaches evaluate individual training sessions. To do this, we will:\n",
        "\n",
        "- Extract the maximum values for each parameter for every player.\n",
        "- Visualize the playerâ€™s performance in a single session.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "DuOQRL4m-tcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zoom_df.loc[:, 'acc_dec_cnt'] = zoom_df.acc_cnt + zoom_df.dec_cnt"
      ],
      "metadata": {
        "id": "T3Poy1pfzKHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind_week_4_df = zoom_df[(zoom_df.date >= date_from) & (zoom_df.date <= date_until)]"
      ],
      "metadata": {
        "id": "gacChHdUzBbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_max_for_player(all_sessions_df: pd.DataFrame, player_name: str, feature_name: str) -> float:\n",
        "  player_session_df = all_sessions_df[all_sessions_df.player == player_name]\n",
        "  return player_session_df[feature_name].max()\n",
        "\n",
        "def extract_max_features(all_sessions_df: pd.DataFrame, players_list: list, param_name: str) -> list:\n",
        "  max_features = []\n",
        "  for p in players_list:\n",
        "    value = extract_max_for_player(all_sessions_df, p, param_name)\n",
        "    if value == 0:\n",
        "      value = all_sessions_df[param_name].max()\n",
        "    max_features.append(value)\n",
        "  return max_features"
      ],
      "metadata": {
        "id": "TZKoW7s1zaxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_colors_and_percentages(session_values: list, max_values: list) -> list:\n",
        "  colors = []\n",
        "  percentages = []\n",
        "\n",
        "  COLOR_DICT = {\n",
        "      'low': 'tomato',\n",
        "      'neutral': 'steelblue',\n",
        "      'high': 'forestgreen'\n",
        "  }\n",
        "\n",
        "  for val, max_v in zip(session_values, max_values):\n",
        "    percentage = int(val / max_v * 100)\n",
        "    LOW = 40\n",
        "    HIGH = 80\n",
        "    if percentage < LOW:\n",
        "      color = COLOR_DICT['low']\n",
        "    elif LOW < percentage < HIGH:\n",
        "      color = 'steelblue'\n",
        "    else:\n",
        "      color = COLOR_DICT['high']\n",
        "    colors.append(color)\n",
        "    percentages.append(percentage)\n",
        "  return colors, percentages"
      ],
      "metadata": {
        "id": "jOram-q2zyGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT_COLOR = 'lightgrey'\n",
        "plt.rcParams['text.color'] = TEXT_COLOR\n",
        "plt.rcParams['axes.labelcolor'] = TEXT_COLOR\n",
        "plt.rcParams['xtick.color'] = TEXT_COLOR\n",
        "plt.rcParams['ytick.color'] = TEXT_COLOR"
      ],
      "metadata": {
        "id": "SNZZQEJ7z0hP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_colums = ['total_distance_m', 'HI_m', 'acc_dec_cnt', 'player_load']"
      ],
      "metadata": {
        "id": "VAHeA_s31PlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session_date = ind_week_4_df.date.iloc[-1]\n",
        "session_df = ind_week_4_df[ind_week_4_df.date == session_date]\n",
        "players = session_df.player.unique()\n",
        "\n",
        "num_columns = 4\n",
        "num_players = players.shape[0]\n",
        "fig, axs = plt.subplots(figsize=(10, 6), nrows=1, ncols=num_columns)\n",
        "facecolor = \"#00001a\"\n",
        "fig.set_facecolor(facecolor)\n",
        "\n",
        "\n",
        "fig.suptitle(f'Session report {session_date}', fontsize=18, weight='bold')\n",
        "\n",
        "ax_count = 0\n",
        "for param, ax in zip(report_colums, axs.reshape(-1)):\n",
        "  max_features = extract_max_features(zoom_df, players, param)\n",
        "\n",
        "  separation_factor = 2\n",
        "\n",
        "  session_param_values = session_df[param].values\n",
        "  colors, percentages = get_colors_and_percentages(session_param_values, max_features)\n",
        "  ax.barh(players, max_features, align='center', color='gray', height=0.6, label='Max')\n",
        "  ax.barh(players, session_param_values, align='center', color=colors, height=0.4, label='Session')\n",
        "\n",
        "  for cnt, info in enumerate(zip(session_param_values, percentages)):\n",
        "    value, percentage = info\n",
        "    ax.text(y=cnt - 0.1, x=value / 2, s=f'{percentage}%', fontsize=10)\n",
        "\n",
        "  ax.yaxis.set_tick_params(labelsize=10)\n",
        "  ax.xaxis.set_tick_params(labelsize=10)\n",
        "\n",
        "  y_tick_labels = ax.get_yticklabels()\n",
        "  for y_tick_label in y_tick_labels:\n",
        "    y_tick_label.set_fontweight('bold')\n",
        "\n",
        "  if ax_count % num_columns != 0:\n",
        "    ax.axes.yaxis.set_ticklabels([])\n",
        "  ax_count += 1\n",
        "  ax.set_facecolor(facecolor)\n",
        "  ax.set_title(param, fontsize=14)"
      ],
      "metadata": {
        "id": "-f2dRCxYz3lO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thank you for your attention and dedication throughout this process. Your efforts in analyzing and understanding the data will be crucial in improving performance and supporting the coaching staff. Keep up the great work!"
      ],
      "metadata": {
        "id": "cK6hNL-wV_Np"
      }
    }
  ]
}